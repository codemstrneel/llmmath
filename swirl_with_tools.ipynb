{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import sympy as sp\n",
    "import requests\n",
    "from typing import List, Dict, Any\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline, PreTrainedModel, PreTrainedTokenizerFast\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "LLM_MODEL = \"gemma-2-27b\"  # Placeholder model\n",
    "REWARD_MODEL = \"gemma-2-27b\"  # Placeholder model\n",
    "SEARCH_API_KEY = \"YOUR_SEARCH_API_KEY\"\n",
    "MAX_HOTPOT_STEPS = 5\n",
    "MAX_GSM8K_STEPS = 10\n",
    "\n",
    "query_tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL)\n",
    "query_model = AutoModelForCausalLM.from_pretrained(LLM_MODEL)\n",
    "query_pipe = pipeline(\"text-generation\", model=query_model, tokenizer=query_tokenizer, device=device)\n",
    "\n",
    "reward_tokenizer = AutoTokenizer.from_pretrained(REWARD_MODEL)\n",
    "reward_model = AutoModelForCausalLM.from_pretrained(REWARD_MODEL)\n",
    "\n",
    "# Should be dictionary of form {tool_name: tool_function}\n",
    "tools_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_model(prompt):\n",
    "    return query_pipe(prompt)[0][\"generated_text\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompting templates\n",
    "def tool_prompt():\n",
    "    return f'''You have access to two tools. To execute some Python code, please wrap the code you want to execute in tags like this: <exec>[CODE]</exec>. The code should be fully self-contained and will be executed in a separate Python file as a main script. To query an external reasoning model with advanced question-answering capabilities, please wrap the query you want to execute in tags like this: <query>[QUERY]</query>. You may only use at most one tool call in your output; the output of the tool call will be appended to the prompt the next time you are queried'''\n",
    "\n",
    "def trajectory_history_prompt(trajectory):\n",
    "    traj = \"\"\n",
    "    for i in range(len(trajectory)):\n",
    "        traj += f\"Attempt {i + 1}:\\n{trajectory[i]}\\n\"\n",
    "    return f'''The entire history of your previous outputs when generating this problem, its test cases, and solution, is presented below.\\n{traj}'''\n",
    "\n",
    "def mutation_prompt(problem):\n",
    "    return f'''Please increase the difficulty of the given programming test question a bit. Do not provide any hints, solutions or outputs. Only one new instruction is allowed. Additionally, generate rationales for what new concepts your problem is designed to test, and how these make it harder. Ensure that you include the <|New Question Begin|>, <|New Question End|>, <|Rationales Begin|>, <|Rationales End|> tags as depicted.\n",
    "{tool_prompt()}\n",
    "Original Question: {problem}\n",
    "\n",
    "### Prompt Template\n",
    "<|New Question Begin|>\n",
    "[New Question]\n",
    "<|New Question End|>\n",
    "<|Rationales Begin|>\n",
    "[Rationales for New Question]\n",
    "<|Rationales End|>\n",
    "'''\n",
    "\n",
    "def generate_test_prompt(problem):\n",
    "    return f'''Please generate unit tests that can be used to verify a solution to this problem. The entire chat history of your previous attempts to generate questions and unit tests is presented below in the \"Chat History\" section, along with the output of running your solution against your tests in a code execution environment. Please modify only your tests and/or solution to be more correct.\n",
    "\n",
    "Question: {problem}\n",
    "\n",
    "### Prompt Template\n",
    "<|New Question Begin|>\n",
    "[New Question]\n",
    "<|New Question End|>\n",
    "<|Rationales Begin|>\n",
    "[Rationales for New Question]\n",
    "<|Rationales End|>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get AI response\n",
    "def get_openai_response(prompt, model=\"gpt-4o\", log_file=\"./api_log_swirl.txt\"):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        msg = response.choices[0].message.content.strip()\n",
    "\n",
    "        if log_file != None:\n",
    "            with open(log_file, \"a\") as f:\n",
    "                f.write(\"PROMPT:\\n\\n\" + prompt + \"\\n\\n\" + \"RESPONSE\\n\\n\" + msg + \"\\n\\n\")\n",
    "\n",
    "        return msg\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "def parse_tag(text, tag):\n",
    "    pattern = f\"<\\|{tag} Begin\\|>(.*?)<\\|{tag} End\\|>\"\n",
    "    return re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "def parse_tool_calls():\n",
    "    return\n",
    "\n",
    "def mutate(problem):\n",
    "    output = query_model(mutation_prompt(problem))\n",
    "    parse_tag()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool calls\n",
    "def execute_tool(tool, payload):\n",
    "    if tool == 'query':\n",
    "        \n",
    "    elif tool == 'execute'\n",
    "\n",
    "    else:\n",
    "        raise(f\"Tried to use nonexistent tool {tool}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trajectory(seed_problem, api_model=\"gpt-4o\"):\n",
    "\n",
    "\n",
    "def generate_mutation_trajectory(seed_problem, num_iterations):\n",
    "    trajectory = []\n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
