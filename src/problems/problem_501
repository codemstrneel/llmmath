QUESTION

**New Question:**

Write a Python function that processes a given list of strings, where each string is a URL, and performs the following tasks:

1. Extract the protocol, domain, and path from each URL using regular expressions and store them in a dictionary with keys 'protocol', 'domain', and 'path'.

2. For each URL, count the total number of alphabets, digits, special characters, and Unicode characters within the entire URL string. Return these counts in a nested dictionary structure, with the URL as the key and a dictionary of counts as the value.

The function should be robust in handling various URL formats and return a list of dictionaries, where each dictionary corresponds to one URL and includes the structured breakdown of the URL components and character counts.

SOL & TESTS

Sure! Here we'll develop a Python function to process a list of URLs, extract their components, and count different types of characters within them. Afterward, we will provide unit tests using pytest.

<|Solution Begin|>
```python
import re

def process_urls(urls):
    results = []
    url_pattern = re.compile(r'(?P<protocol>https?)://(?P<domain>[^/]+)(?P<path>/.*)?')

    for url in urls:
        match = url_pattern.match(url)
        if match:
            protocol = match.group('protocol')
            domain = match.group('domain')
            path = match.group('path') or ''
        else:
            protocol = domain = path = ''

        counts = {
            'alphabets': sum(c.isalpha() for c in url),
            'digits': sum(c.isdigit() for c in url),
            'special': sum(not c.isalnum() for c in url),
            'unicode': sum(c.isascii() is False for c in url)
        }

        result = {
            'url': url,
            'components': {
                'protocol': protocol,
                'domain': domain,
                'path': path
            },
            'counts': counts
        }

        results.append(result)

    return results
```
<|Solution End|>

<|Test Begin|>
```python
from solution import process_urls

def test_process_urls_basic():
    urls = ['http://example.com/path', 'https://sub.domain.co.uk/more?query=1']
    results = process_urls(urls)
    assert len(results) == 2
    
    assert results[0]['components'] == {'protocol': 'http', 'domain': 'example.com', 'path': '/path'}
    assert results[0]['counts']['alphabets'] == 19
    assert results[0]['counts']['digits'] == 0
    assert results[0]['counts']['special'] == 5
    assert results[0]['counts']['unicode'] == 0

    assert results[1]['components'] == {'protocol': 'https', 'domain': 'sub.domain.co.uk', 'path': '/more?query=1'}
    assert results[1]['counts']['alphabets'] == 28
    assert results[1]['counts']['digits'] == 1
    assert results[1]['counts']['special'] == 6
    assert results[1]['counts']['unicode'] == 0

def test_process_urls_no_protocol():
    urls = ['example.com/path']
    results = process_urls(urls)
    assert len(results) == 1
    assert results[0]['components'] == {'protocol': '', 'domain': '', 'path': ''}
    assert results[0]['counts']['alphabets'] == 12
    assert results[0]['counts']['digits'] == 0
    assert results[0]['counts']['special'] == 1
    assert results[0]['counts']['unicode'] == 0

def test_process_urls_with_unicode():
    urls = ['http://例子.测试/路径']
    results = process_urls(urls)
    assert len(results) == 1
    assert results[0]['components'] == {'protocol': 'http', 'domain': '例子.测试', 'path': '/路径'}
    assert results[0]['counts']['alphabets'] == 0
    assert results[0]['counts']['digits'] == 0
    assert results[0]['counts']['special'] == 4
    assert results[0]['counts']['unicode'] == 6

def test_process_urls_empty():
    urls = []
    results = process_urls(urls)
    assert len(results) == 0
```
<|Test End|>

The function `process_urls` extracts protocol, domain, and path using regex and counts the types of characters present in URLs. The tests ensure that it correctly processes these components and character counts, even for URLs without a clear protocol and those containing Unicode characters.