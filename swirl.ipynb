{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import sympy as sp\n",
    "import requests\n",
    "from typing import List, Dict, Any\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline, PreTrainedModel, PreTrainedTokenizerFast\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "from torch.distributions import Categorical\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.88s/it]\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "LLM_MODEL = \"google/gemma-2-2b-it\" \n",
    "REWARD_MODEL = \"google/gemma-2-2b-it\"\n",
    "MAX_HOTPOT_STEPS = 5\n",
    "MAX_GSM8K_STEPS = 10\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL)\n",
    "model = AutoModelForCausalLM.from_pretrained(LLM_MODEL).to(device)\n",
    "# query_pipe = pipeline(\"text-generation\", model=query_model, tokenizer=query_tokenizer, device=device)\n",
    "\n",
    "reward_tokenizer = AutoTokenizer.from_pretrained(REWARD_MODEL)\n",
    "reward_model = AutoModelForCausalLM.from_pretrained(REWARD_MODEL)\n",
    "\n",
    "# Should be dictionary of form {tool_name: tool_function}\n",
    "tools_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_history_prompt(trajectory):\n",
    "    traj = \"Chat History:\\n\"\n",
    "    for i in range(len(trajectory)):\n",
    "        traj += f\"Attempt {i + 1}:\\n{trajectory[i]}\\n\"\n",
    "    return f'''The entire history of your previous outputs when generating this problem, its test cases, and solution, is presented below.\\n{traj}'''\n",
    "\n",
    "def mutation_prompt(problem):\n",
    "    print(problem)\n",
    "    return f'''Please mutate this question to increase the difficulty of it. The new question should be sufficiently different and not be a paraphrased version of the original question. Do not provide any hints, solutions or outputs. Only one new instruction is allowed. Additionally, generate rationales for what changes you have made, and how these make the problem harder or more correct. Ensure that you include the <|New Question Begin|>, <|New Question End|>, <|Rationales Begin|>, <|Rationales End|> tags as depicted.\n",
    "Question: {problem}\n",
    "\n",
    "### Prompt Template\n",
    "<|New Question Begin|>\n",
    "[New Question]\n",
    "<|New Question End|>\n",
    "<|Rationales Begin|>\n",
    "[Rationales for Thinking]\n",
    "<|Rationales End|>\n",
    "'''\n",
    "\n",
    "def test_prompt(problem, trajectory):\n",
    "    return f'''Please generate unit tests that can be used to verify a solution to this problem in the format within the specified section below. The entire chat history of your previous attempts to generate questions and unit tests is presented below in the \"Chat History\" section below. Please place the problem in the appropriate tags in the template; you may modify it to more appropriately match edge-cases in the tests, but do not change the core idea of the problem. Ensure your code is within code blocks. For the tests, use pytest style by defining individual test functions (without classes) and using assert statements. Your tests should be implementation independent and assume the solution function is called \"solution\".\n",
    "Question: {problem}\n",
    "\n",
    "### Prompt Template\n",
    "<|Question Begin|>\n",
    "[New Question]\n",
    "<|Question End|>\n",
    "<|Rationales Begin|>\n",
    "[Rationales for Thinking]\n",
    "<|Rationales End|>\n",
    "<|Test Begin|>\n",
    "[Unit Test Code in Python]\n",
    "<|Test End|>\n",
    "{trajectory_history_prompt(trajectory)}\n",
    "'''\n",
    "\n",
    "def sol_prompt(problem, trajectory):\n",
    "    return f'''Please generate a solution to the given question in the specified section below. The entire chat history of your previous attempts to generate questions, unit tests, and solutions is presented below in the \"Chat History\" section below. Please place the problem in the appropriate tags in the template; you may modify it to more appropriately match edge-cases in the tests, but do not change the core idea of the problem. Ensure your code is within code blocks. For the tests, use pytest style by defining individual test functions (without classes) and using assert statements. You may modify the tests to better fit the problem and solution, but do not reduce coverage or any edge-cases. Your solution should be a function called \"solution\". Your tests will be ran against your solution in a code execution environment and the result will be given to you in the next query \n",
    "Question: {problem}\n",
    "\n",
    "### Prompt Template\n",
    "<|Question Begin|>\n",
    "[New Question]\n",
    "<|Question End|>\n",
    "<|Rationales Begin|>\n",
    "[Rationales for Thinking]\n",
    "<|Rationales End|>\n",
    "<|Test Begin|>\n",
    "[Unit Test Code in Python]\n",
    "<|Test End|>\n",
    "<|Solution Begin|>\n",
    "[Solution Code in Python]\n",
    "<|Solution End|>\n",
    "{trajectory_history_prompt(trajectory)}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get AI response\n",
    "def get_openai_response(prompt, model=\"o3-mini\", log_file=\"./api_log_swirl.txt\"):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        msg = response.choices[0].message.content.strip()\n",
    "\n",
    "        if log_file != None:\n",
    "            with open(log_file, \"a\") as f:\n",
    "                f.write(\"PROMPT:\\n\\n\" + prompt + \"\\n\\n\" + \"RESPONSE\\n\\n\" + msg + \"\\n\\n\")\n",
    "\n",
    "        return msg\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "def query_model(prompt, log_file=\"./api_log_swirl.txt\"):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    output = tokenizer.decode(model.generate(**input_ids, max_new_tokens=256)[0])\n",
    "    if log_file != None:\n",
    "            with open(log_file, \"a\") as f:\n",
    "                f.write(\"PROMPT:\\n\\n\" + prompt + \"\\n\\n\" + \"RESPONSE\\n\\n\" + output + \"\\n\\n\")\n",
    "    return output\n",
    "\n",
    "def parse_tag(text, tag):\n",
    "    pattern = r\"<\\|\" + tag + r\" Begin\\|>(.*?)<\\|\" + tag + r\" End\\|>\"\n",
    "    return re.findall(pattern, text, re.DOTALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncPage[Model](data=[Model(id='gpt-4o-audio-preview-2024-12-17', created=1734034239, object='model', owned_by='system'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2024-10-01', created=1727389042, object='model', owned_by='system'), Model(id='o3-mini-2025-01-31', created=1738010200, object='model', owned_by='system'), Model(id='o3', created=1744225308, object='model', owned_by='system'), Model(id='o3-mini', created=1737146383, object='model', owned_by='system'), Model(id='o3-2025-04-16', created=1744133301, object='model', owned_by='system'), Model(id='o4-mini', created=1744225351, object='model', owned_by='system'), Model(id='gpt-4.1-nano', created=1744321707, object='model', owned_by='system'), Model(id='gpt-4.1-nano-2025-04-14', created=1744321025, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-10-01', created=1727131766, object='model', owned_by='system'), Model(id='o4-mini-2025-04-16', created=1744133506, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview', created=1727659998, object='model', owned_by='system'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview', created=1734387424, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview', created=1727460443, object='model', owned_by='system'), Model(id='o1-preview-2024-09-12', created=1725648865, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview', created=1734387380, object='model', owned_by='system'), Model(id='gpt-4.1-mini', created=1744318173, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview-2024-12-17', created=1734112601, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'), Model(id='gpt-4o-mini-search-preview', created=1741391161, object='model', owned_by='system'), Model(id='gpt-4.1-mini-2025-04-14', created=1744317547, object='model', owned_by='system'), Model(id='computer-use-preview-2025-03-11', created=1741377021, object='model', owned_by='system'), Model(id='chatgpt-4o-latest', created=1723515131, object='model', owned_by='system'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='gpt-4o-search-preview', created=1741388720, object='model', owned_by='system'), Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-12-17', created=1733945430, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='gpt-4o-mini-search-preview-2025-03-11', created=1741390858, object='model', owned_by='system'), Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'), Model(id='gpt-4o-2024-11-20', created=1739331543, object='model', owned_by='system'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'), Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='o1-preview', created=1725648897, object='model', owned_by='system'), Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='gpt-4.5-preview', created=1740623059, object='model', owned_by='system'), Model(id='gpt-4.5-preview-2025-02-27', created=1740623304, object='model', owned_by='system'), Model(id='gpt-4o-search-preview-2025-03-11', created=1741388170, object='model', owned_by='system'), Model(id='omni-moderation-2024-09-26', created=1732734466, object='model', owned_by='system'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'), Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system'), Model(id='gpt-4.1', created=1744316542, object='model', owned_by='system'), Model(id='gpt-4o-transcribe', created=1742068463, object='model', owned_by='system'), Model(id='gpt-4.1-2025-04-14', created=1744315746, object='model', owned_by='system'), Model(id='o1', created=1734375816, object='model', owned_by='system'), Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system'), Model(id='o1-pro-2025-03-19', created=1742251504, object='model', owned_by='system'), Model(id='gpt-4o-mini-transcribe', created=1742068596, object='model', owned_by='system'), Model(id='o1-pro', created=1742251791, object='model', owned_by='system'), Model(id='o1-mini', created=1725649008, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview-2024-12-17', created=1734115920, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='o1-mini-2024-09-12', created=1725648979, object='model', owned_by='system'), Model(id='o1-2024-12-17', created=1734326976, object='model', owned_by='system'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='gpt-4o-mini-tts', created=1742403959, object='model', owned_by='system'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='computer-use-preview', created=1734655677, object='model', owned_by='system'), Model(id='omni-moderation-latest', created=1731689265, object='model', owned_by='system'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math500:BCnW6jpD:ckpt-step-100', created=1742389978, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math500:BCnW6v48:ckpt-step-200', created=1742389979, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math500:BCnW8Lud', created=1742389980, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math500:BCnW7PNz', created=1742389979, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math500:BCnW77NO:ckpt-step-100', created=1742389980, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math500:BCnW8Rgf:ckpt-step-200', created=1742389980, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math500:BCYxtmQ7:ckpt-step-60', created=1742334041, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math500:BCYxtGHV:ckpt-step-75', created=1742334042, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math500:BCYxutuZ', created=1742334042, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math500:BChOVqP0:ckpt-step-99', created=1742366443, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math500:BChOVROm:ckpt-step-198', created=1742366444, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math500:BChOWIHH', created=1742366444, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math500:BChOXchV:ckpt-step-97', created=1742366445, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math500:BChOXDji:ckpt-step-194', created=1742366445, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math500:BChOXV6f', created=1742366446, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math500:BCWHU7ZF', created=1742323725, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math:BANmcNqb:ckpt-step-100', created=1741814402, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math:BANmcWxr:ckpt-step-200', created=1741814402, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math:BANmcSWn', created=1741814403, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math:BANmwt1F:ckpt-step-100', created=1741814422, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math:BANmwVAP:ckpt-step-200', created=1741814422, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math:BANmxyj9', created=1741814423, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math:BAOUHucF:ckpt-step-100', created=1741817109, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math:BAOUHhaj:ckpt-step-200', created=1741817109, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math:BAOUH1Ae', created=1741817110, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math:BAOUJBVD:ckpt-step-100', created=1741817111, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math:BAOUJFzu:ckpt-step-200', created=1741817111, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math:BAOUKah7', created=1741817112, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math-3:BARLgYaf:ckpt-step-63', created=1741828109, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math-3:BARLhFBB:ckpt-step-126', created=1741828109, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math-3:BARLhR87', created=1741828109, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math-3:BARMV3Gf:ckpt-step-83', created=1741828159, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math-3:BARMVy1b:ckpt-step-166', created=1741828159, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math-3:BARMVfPx', created=1741828159, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-4o-2024-08-06:sunblaze:preference-trainer:BCoRii6u:ckpt-step-100', created=1742393550, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-4o-2024-08-06:sunblaze:preference-trainer:BCoRiXnX:ckpt-step-200', created=1742393551, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-4o-2024-08-06:sunblaze:preference-trainer:BCoRjivJ', created=1742393551, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math500:BCWHUAWC:ckpt-step-60', created=1742323724, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math500:BCWHUYxu:ckpt-step-75', created=1742323724, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-4o-2024-08-06:sunblaze:preference-trainer:BCJJs2IQ:ckpt-step-56', created=1742273900, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-4o-2024-08-06:sunblaze:preference-trainer:BCJJsoeS:ckpt-step-112', created=1742273900, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-4o-2024-08-06:sunblaze:preference-trainer:BCJJtLU3', created=1742273901, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-4o-2024-08-06:sunblaze:preference-trainer:BCiRNZrz:ckpt-step-96', created=1742370466, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-4o-2024-08-06:sunblaze:preference-trainer:BCiROhXr:ckpt-step-192', created=1742370466, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-4o-2024-08-06:sunblaze:preference-trainer:BCiROVEn', created=1742370466, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math500:BCBgCU7Y:ckpt-step-112', created=1742244532, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math500:BCBh2kkZ', created=1742244585, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math500:BCinnfqq:ckpt-step-98', created=1742371855, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math500:BCinn0Rf:ckpt-step-98', created=1742371855, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math500:BCinnQwQ:ckpt-step-196', created=1742371855, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math500:BCinn4FW:ckpt-step-196', created=1742371856, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math500:BCinnuBH', created=1742371856, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math500:BCino9vR', created=1742371856, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math500:BCBgCcUU:ckpt-step-56', created=1742244532, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:creative-math500:BCBgDd2e', created=1742244533, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math500:BCBh2VMp:ckpt-step-61', created=1742244584, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-3.5-turbo-0125:sunblaze:direct-math500:BCBh2rCo:ckpt-step-122', created=1742244584, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-4o-2024-08-06:sunblaze:preference-trainer:BCjXR97C', created=1742374685, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-4o-2024-08-06:sunblaze:preference-trainer:BCjXQjKQ:ckpt-step-98', created=1742374685, object='model', owned_by='sunblaze-ac35od'), Model(id='ft:gpt-4o-2024-08-06:sunblaze:preference-trainer:BCjXRgG0:ckpt-step-196', created=1742374685, object='model', owned_by='sunblaze-ac35od')], object='list')\n",
      "Write a function to find the most common elements and their counts of a specified text, excluding any elements that appear in the provided list of excluded words.\n",
      "Error: Error code: 400 - {'error': {'message': 'invalid model ID', 'type': 'invalid_request_error', 'param': None, 'code': None}} [] []\n"
     ]
    }
   ],
   "source": [
    "def generate(seed_problem):\n",
    "    response = query_model(mutation_prompt(seed_problem))\n",
    "    question = parse_tag(response, \"Question\")\n",
    "    rationales = parse_tag(response, \"Rationales\")\n",
    "\n",
    "    trajectory = [response]\n",
    "\n",
    "    for i in range(2):\n",
    "        response = query_model(test_prompt(question, trajectory))\n",
    "        question = parse_tag(response, \"Question\")\n",
    "        rationales = parse_tag(response, \"Rationales\")\n",
    "        tests = parse_tag(response, \"Tests\")\n",
    "        trajectory.append(response)\n",
    "\n",
    "    for i in range(2):\n",
    "        response = query_model(sol_prompt(question, trajectory))\n",
    "        question = parse_tag(response, \"Question\")\n",
    "        rationales = parse_tag(response, \"Rationales\")\n",
    "        tests = parse_tag(response, \"Tests\")\n",
    "        solution = parse_tag(response, \"Solution\")\n",
    "        trajectory.append(response)\n",
    "    \n",
    "    print(response, question, solution)\n",
    "\n",
    "print(client.models.list())\n",
    "generate(\"Write a function to find the most common elements and their counts of a specified text, excluding any elements that appear in the provided list of excluded words.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # This is just a start, hasnt been tested at all\n",
    " DISCOUNT_FACTOR = 0.99\n",
    " \n",
    " def compute_rewards(self, seed_question, trajectory) -> float:\n",
    "    '''Compute the rewards for every state in the trajectory'''\n",
    "        ''' TODO: I think a good initial test would include\n",
    "        - Penalize the model for changing the question after the initial mutation (could probably detect this with BeRT embedding cosine simliarity)\n",
    "        - Penalize the model for changing tests after test generation stage\n",
    "        - Penalize the model for failing tests during solution generation (these should all be binary probably) \n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def train_on_trajectory(self, seed_question, trajectory: List[Dict[str, Any]]):\n",
    "        log_probs = []\n",
    "        rewards = compute_rewards(seed_question, trajectory)\n",
    "        for step in trajectory:\n",
    "            inputs = query_tokenizer(step, return_tensors='pt').to(self.model.device)\n",
    "            outputs = self.model(**inputs)\n",
    "            logits = outputs.logits[:, -1, :]\n",
    "            dist = Categorical(logits=logits)\n",
    "\n",
    "        # Compute cumulative reward\n",
    "        cumulative = 0\n",
    "        returns = []\n",
    "        for r in reversed(rewards):\n",
    "            cumulative = r + DISCOUNT_FACTOR * cumulative\n",
    "            returns.insert(0, cumulative)\n",
    "        returns = torch.tensor(returns)\n",
    "        log_probs = torch.stack(log_probs)\n",
    "\n",
    "        loss = -(log_probs * returns).sum()\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
